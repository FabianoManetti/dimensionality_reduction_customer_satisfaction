{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction - Customer Satisfaction Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://github.com/FabianoManetti/dimensionality_reduction_customer_satisfaction/customer_satisfaction.jpg\" width=\"400\" height=\"400\"></center><br>\n",
    "\n",
    "It is essential for Banks to monitor their **Customers' Satisfaction** since dissatisfied customers tend to cancel their services with that institution and are likely to migrate to another bank.\n",
    "\n",
    "Santander Bank was asking Data Scientists to help them identify dissatisfied customers at the beggining of the relationship. This would allow Santander to create proactive measures in order to retain that client.\n",
    "\n",
    "For this project, it was requested an **accuracy of, at least, 70%**.\n",
    "\n",
    "The dataset consists of many anonymous features from different customers that will demand the use of **dimensionality reduction** tools.\n",
    "\n",
    "üè¶ **Objectives**\n",
    "* Import and treat the data\n",
    "* Reduce the number of features\n",
    "* Achieve the minimum score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TcCFiDqsHkbc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from yellowbrick.model_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "-psOZXjIJZkJ",
    "outputId": "cfcd6eaa-506b-4a8d-f4b8-bf50bcf79d03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39929</th>\n",
       "      <td>79902</td>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11641</th>\n",
       "      <td>23345</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102190.650000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51663</th>\n",
       "      <td>103179</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99436.020000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>13688</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58921.260000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33730</th>\n",
       "      <td>67460</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88649.610000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34196</th>\n",
       "      <td>68358</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159606.540000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22956</th>\n",
       "      <td>45907</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101031.900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36579</th>\n",
       "      <td>73093</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16332</th>\n",
       "      <td>32799</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>420822.780000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46772</th>\n",
       "      <td>93525</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>90.0</td>\n",
       "      <td>419.94</td>\n",
       "      <td>963.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137372.760000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "39929   79902    10     85                 0.0                     0.00   \n",
       "11641   23345     2     34                 0.0                     0.00   \n",
       "51663  103179     2     23                 0.0                     0.00   \n",
       "6820    13688     2     24                 0.0                     0.00   \n",
       "33730   67460     2     25                 0.0                     0.00   \n",
       "34196   68358     2     51                 0.0                     0.00   \n",
       "22956   45907     2     74                 0.0                     0.00   \n",
       "36579   73093     2     35                 0.0                     0.00   \n",
       "16332   32799     2     27                 0.0                     0.00   \n",
       "46772   93525     2     53                90.0                   419.94   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "39929                     0.00                      0.0   \n",
       "11641                     0.00                      0.0   \n",
       "51663                     0.00                      0.0   \n",
       "6820                      0.00                      0.0   \n",
       "33730                     0.00                      0.0   \n",
       "34196                     0.00                      0.0   \n",
       "22956                     0.00                      0.0   \n",
       "36579                     0.00                      0.0   \n",
       "16332                     0.00                      0.0   \n",
       "46772                   963.24                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "39929                      0.0                      0.0   \n",
       "11641                      0.0                      0.0   \n",
       "51663                      0.0                      0.0   \n",
       "6820                       0.0                      0.0   \n",
       "33730                      0.0                      0.0   \n",
       "34196                      0.0                      0.0   \n",
       "22956                      0.0                      0.0   \n",
       "36579                      0.0                      0.0   \n",
       "16332                      0.0                      0.0   \n",
       "46772                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  ...  saldo_medio_var33_hace2  \\\n",
       "39929                      0.0  ...                      0.0   \n",
       "11641                      0.0  ...                      0.0   \n",
       "51663                      0.0  ...                      0.0   \n",
       "6820                       0.0  ...                      0.0   \n",
       "33730                      0.0  ...                      0.0   \n",
       "34196                      0.0  ...                      0.0   \n",
       "22956                      0.0  ...                      0.0   \n",
       "36579                      0.0  ...                      0.0   \n",
       "16332                      0.0  ...                      0.0   \n",
       "46772                      0.0  ...                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "39929                      0.0                     0.0   \n",
       "11641                      0.0                     0.0   \n",
       "51663                      0.0                     0.0   \n",
       "6820                       0.0                     0.0   \n",
       "33730                      0.0                     0.0   \n",
       "34196                      0.0                     0.0   \n",
       "22956                      0.0                     0.0   \n",
       "36579                      0.0                     0.0   \n",
       "16332                      0.0                     0.0   \n",
       "46772                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "39929                     0.0                      0.0   \n",
       "11641                     0.0                      0.0   \n",
       "51663                     0.0                      0.0   \n",
       "6820                      0.0                      0.0   \n",
       "33730                     0.0                      0.0   \n",
       "34196                     0.0                      0.0   \n",
       "22956                     0.0                      0.0   \n",
       "36579                     0.0                      0.0   \n",
       "16332                     0.0                      0.0   \n",
       "46772                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "39929                      0.0                     0.0   \n",
       "11641                      0.0                     0.0   \n",
       "51663                      0.0                     0.0   \n",
       "6820                       0.0                     0.0   \n",
       "33730                      0.0                     0.0   \n",
       "34196                      0.0                     0.0   \n",
       "22956                      0.0                     0.0   \n",
       "36579                      0.0                     0.0   \n",
       "16332                      0.0                     0.0   \n",
       "46772                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  TARGET  \n",
       "39929                     0.0  117310.979016       0  \n",
       "11641                     0.0  102190.650000       0  \n",
       "51663                     0.0   99436.020000       0  \n",
       "6820                      0.0   58921.260000       0  \n",
       "33730                     0.0   88649.610000       0  \n",
       "34196                     0.0  159606.540000       0  \n",
       "22956                     0.0  101031.900000       0  \n",
       "36579                     0.0  117310.979016       0  \n",
       "16332                     0.0  420822.780000       0  \n",
       "46772                     0.0  137372.760000       0  \n",
       "\n",
       "[10 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training dataset:\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CzVVGOdJfu_",
    "outputId": "e52220ce-e941-4ee6-d204-f66523a3f6d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training dataset dimension:\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwUZtyQn9HCm",
    "outputId": "621a22da-e526-4f95-e059-bc50a72921b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping any duplicate value:\n",
    "\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "yngk-oM7Jien",
    "outputId": "0d66cf82-d677-435a-ff6e-9be811fd8e95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34588</th>\n",
       "      <td>69225</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198938.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7484</th>\n",
       "      <td>14950</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82543.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34264</th>\n",
       "      <td>68587</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77239.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19808</th>\n",
       "      <td>39522</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65221.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62319</th>\n",
       "      <td>124855</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300609.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65865</th>\n",
       "      <td>131942</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22466</th>\n",
       "      <td>44868</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79595.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10277</th>\n",
       "      <td>20512</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65128.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31852</th>\n",
       "      <td>63765</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77919.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28001</th>\n",
       "      <td>55984</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>493838.460000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "34588   69225     2     31                 0.0                      0.0   \n",
       "7484    14950     2     27                 0.0                      0.0   \n",
       "34264   68587     2     51                 0.0                      0.0   \n",
       "19808   39522     2     23                 0.0                      0.0   \n",
       "62319  124855     2     23                 0.0                      0.0   \n",
       "65865  131942     2     23                 0.0                      0.0   \n",
       "22466   44868     2     23                 0.0                      0.0   \n",
       "10277   20512     2     61                 0.0                      0.0   \n",
       "31852   63765     2     23                 0.0                      0.0   \n",
       "28001   55984     2     34                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "34588                      0.0                      0.0   \n",
       "7484                       0.0                      0.0   \n",
       "34264                      0.0                      0.0   \n",
       "19808                      0.0                      0.0   \n",
       "62319                      0.0                      0.0   \n",
       "65865                      0.0                      0.0   \n",
       "22466                      0.0                      0.0   \n",
       "10277                      0.0                      0.0   \n",
       "31852                      0.0                      0.0   \n",
       "28001                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "34588                      0.0                      0.0   \n",
       "7484                       0.0                      0.0   \n",
       "34264                      0.0                      0.0   \n",
       "19808                      0.0                      0.0   \n",
       "62319                      0.0                      0.0   \n",
       "65865                      0.0                      0.0   \n",
       "22466                      0.0                      0.0   \n",
       "10277                      0.0                      0.0   \n",
       "31852                      0.0                      0.0   \n",
       "28001                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  ...  saldo_medio_var29_ult3  \\\n",
       "34588                      0.0  ...                     0.0   \n",
       "7484                       0.0  ...                     0.0   \n",
       "34264                      0.0  ...                     0.0   \n",
       "19808                      0.0  ...                     0.0   \n",
       "62319                      0.0  ...                     0.0   \n",
       "65865                      0.0  ...                     0.0   \n",
       "22466                      0.0  ...                     0.0   \n",
       "10277                      0.0  ...                     0.0   \n",
       "31852                      0.0  ...                     0.0   \n",
       "28001                      0.0  ...                     0.0   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "34588                      0.0                      0.0   \n",
       "7484                       0.0                      0.0   \n",
       "34264                      0.0                      0.0   \n",
       "19808                      0.0                      0.0   \n",
       "62319                      0.0                      0.0   \n",
       "65865                      0.0                      0.0   \n",
       "22466                      0.0                      0.0   \n",
       "10277                      0.0                      0.0   \n",
       "31852                      0.0                      0.0   \n",
       "28001                      0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "34588                     0.0                     0.0   \n",
       "7484                      0.0                     0.0   \n",
       "34264                     0.0                     0.0   \n",
       "19808                     0.0                     0.0   \n",
       "62319                     0.0                     0.0   \n",
       "65865                     0.0                     0.0   \n",
       "22466                     0.0                     0.0   \n",
       "10277                     0.0                     0.0   \n",
       "31852                     0.0                     0.0   \n",
       "28001                     0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "34588                      0.0                      0.0   \n",
       "7484                       0.0                      0.0   \n",
       "34264                      0.0                      0.0   \n",
       "19808                      0.0                      0.0   \n",
       "62319                      0.0                      0.0   \n",
       "65865                      0.0                      0.0   \n",
       "22466                      0.0                      0.0   \n",
       "10277                      0.0                      0.0   \n",
       "31852                      0.0                      0.0   \n",
       "28001                      0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  \n",
       "34588                     0.0                     0.0  198938.190000  \n",
       "7484                      0.0                     0.0   82543.890000  \n",
       "34264                     0.0                     0.0   77239.560000  \n",
       "19808                     0.0                     0.0   65221.110000  \n",
       "62319                     0.0                     0.0  300609.240000  \n",
       "65865                     0.0                     0.0  117310.979016  \n",
       "22466                     0.0                     0.0   79595.040000  \n",
       "10277                     0.0                     0.0   65128.830000  \n",
       "31852                     0.0                     0.0   77919.360000  \n",
       "28001                     0.0                     0.0  493838.460000  \n",
       "\n",
       "[10 rows x 370 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing dataset:\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Q70_3u4Kv_Y",
    "outputId": "32e22ea5-161c-4e4a-e0fc-a6973e7bee59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75818, 370)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing dataset dimension: \n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RkUhXtzh9NkP",
    "outputId": "135345b3-a0f7-4185-cff5-83d542848044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75818, 370)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping any duplicate value:\n",
    "\n",
    "df_test = df_test.drop_duplicates()\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by checking if the rows in the testing dataset are different from those in the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JYt66MVfKyl4"
   },
   "outputs": [],
   "source": [
    "test_ID = df_test.ID\n",
    "\n",
    "sum_total = 0\n",
    "\n",
    "for id in test_ID:\n",
    "\n",
    "    sum = df_train[df_train.ID == id].shape[0]\n",
    "\n",
    "    sum_total += sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rMoAe54OP79",
    "outputId": "2fd38924-3eed-460d-e1e5-df04cd884cb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can observe that, in fact, the testing dataset consists of **unique** values.\n",
    "\n",
    "How is our `Target` feature distributed in the training dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YiUDJ_JPG-n",
    "outputId": "7aed9d66-466c-4ad3-942f-e0dd075bf7a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73012\n",
       "1     3008\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The label 1 is related to the **dissatisfied** customers. This way, we observe a majority of data of satisfied customers. Later on, we'll have to use balancing techniques to properly address our problem.\n",
    "\n",
    "We can now check for missing or null values in both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyeRARwVaP3T",
    "outputId": "edc5afb1-bcc6-41d3-9399-9926d4fa6a8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V564CII4A3Ga",
    "outputId": "c11025b4-7422-47b3-d2a3-d5ca1248e959"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3dTYcpleeOW",
    "outputId": "2b809998-7d19-4b0b-bd75-d804a9f6b2cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKjQbdw0A2r4",
    "outputId": "13675b04-a78e-44a6-a937-fea1ec557185"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There isn't any **missing** or **null** value in the training and testing dataset.\n",
    "\n",
    "Since the **testing** dataset does not contain our target features, we decided at this point **not to use it** in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "QGJIpm8HG7sz",
    "outputId": "7190b6fd-a451-49af-d363-f0b9a75dc952"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick statistics:\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reducing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start our work by dropping the `ID` column, since it does not give us useful information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Oiwhqk-5u-QT"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 First reduction: Variance Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **variance** is simply the average of the squared differences from the mean. It is import in the context of machine learning because features with 0 or close to 0 variance are generally **useless** in terms of prediction power.\n",
    "\n",
    "For the purpose of this project, we'll make use of the `VarianceThreshold` estimator. It will select all the features in our dataset whose variance is higher than a set threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "X0ksZuvLYHQz"
   },
   "outputs": [],
   "source": [
    "df_1 = df_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set our threshold as **0.01** for this case. It is necessary to bring all the features to the **same scale** or the estimator will be returning a potencially false output. We can use `MinMaxScaler` inside a `Pipeline` model for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y43OP8IWef_-",
    "outputId": "cf3d42f0-2a7f-40de-b08f-0ea812403715"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18      , 0.        , 1.        , ..., 0.        , 0.66666667,\n",
       "        0.        ],\n",
       "       [0.29      , 0.        , 1.        , ..., 1.        , 0.66666667,\n",
       "        0.        ],\n",
       "       [0.18      , 0.        , 1.        , ..., 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.18      , 0.        , 1.        , ..., 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       [0.2       , 0.        , 1.        , ..., 0.        , 0.66666667,\n",
       "        0.        ],\n",
       "       [0.41      , 0.        , 1.        , ..., 0.        , 0.66666667,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "selector = VarianceThreshold(threshold = 0.01)\n",
    "\n",
    "pipeline = Pipeline([('scaler', scaler), ('selector', selector)])\n",
    "\n",
    "pipeline.fit_transform(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WyZM90ijhYio"
   },
   "outputs": [],
   "source": [
    "# Getting the names of the features that satisfied our condition:\n",
    "\n",
    "columns_df_1 = pipeline.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49yFivoPJSWF",
    "outputId": "0d01e514-543d-4618-e859-dcc504c37b84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['var15', 'ind_var1_0', 'ind_var5_0', 'ind_var5', 'ind_var8_0',\n",
       "       'ind_var8', 'ind_var12_0', 'ind_var12', 'ind_var13_0',\n",
       "       'ind_var13_corto_0', 'ind_var13_corto', 'ind_var13_largo_0',\n",
       "       'ind_var13', 'ind_var14_0', 'ind_var24_0', 'ind_var24',\n",
       "       'ind_var25_cte', 'ind_var26_0', 'ind_var26_cte', 'ind_var26',\n",
       "       'ind_var25_0', 'ind_var25', 'ind_var30', 'ind_var37_cte',\n",
       "       'ind_var37_0', 'ind_var37', 'ind_var39_0', 'ind_var40_0',\n",
       "       'ind_var41_0', 'num_var4', 'num_var8', 'num_var13_corto_0',\n",
       "       'var36', 'ind_var10_ult1', 'ind_var10cte_ult1',\n",
       "       'ind_var9_cte_ult1', 'ind_var9_ult1', 'ind_var43_emit_ult1',\n",
       "       'ind_var43_recib_ult1', 'num_meses_var5_ult3',\n",
       "       'num_meses_var8_ult3', 'num_meses_var12_ult3',\n",
       "       'num_meses_var13_corto_ult3', 'num_meses_var39_vig_ult3', 'TARGET'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hbuDMdnefSH4"
   },
   "outputs": [],
   "source": [
    "# Filtering the first dataframe with these columns:\n",
    "\n",
    "df_1 = df_1.loc[:, columns_df_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KDh856BF0vA",
    "outputId": "e9b41c99-3d5b-49f2-debd-129aa89a43e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 45)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the dimension:\n",
    "\n",
    "df_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We were able to **eliminate** a great number of columns, 325 to be exact. This result shows us that many features in our initial dataframe were potentially useless to be used as predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Second reduction: Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity refers to the occurance of high **intercorrelations** among two or more independent variables. \n",
    "\n",
    "Multicollinearity causes problems in the interpretability of the model result, for this reason it is advisable to drop features that present high correlation with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0m9YJ9xSLkk4"
   },
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the correlation among the features we will use the function `corr`. We'll also establish a correlation threshold of **¬± 0.7** and keep only features in this interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_drop = []\n",
    "\n",
    "for i in df_2.columns:\n",
    "    \n",
    "    for j in df_2.columns:\n",
    "        \n",
    "        if i != j:\n",
    "            \n",
    "            cor  = df_2[i].corr(df_2[j])\n",
    "            \n",
    "            if cor >= 0.7 or cor <= -0.7:\n",
    "                \n",
    "                features = (i, j)\n",
    "                \n",
    "                if features not in pair_drop and tuple(reversed(features)) not in pair_drop:\n",
    "                    \n",
    "                    pair_drop.append(features)\n",
    "                    \n",
    "features_drop = []\n",
    "\n",
    "for i in pair_drop:\n",
    "    \n",
    "    feature = i[0]\n",
    "    \n",
    "    if feature not in features_drop:\n",
    "        \n",
    "        features_drop.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5t0GMqVHcNQi",
    "outputId": "7e04bf31-720b-4c83-ccd6-fd79decd6ab2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var15', 'ind_var13_largo_0', 'ind_var14_0', 'ind_var40_0', 'num_var4',\n",
       "       'var36', 'ind_var9_ult1', 'ind_var43_emit_ult1', 'ind_var43_recib_ult1',\n",
       "       'num_meses_var5_ult3', 'num_meses_var8_ult3', 'num_meses_var12_ult3',\n",
       "       'num_meses_var13_corto_ult3', 'num_meses_var39_vig_ult3', 'TARGET'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = df_2.drop(columns = features_drop)\n",
    "\n",
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Once again, we were able to **reduce** the dimensionality of the dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Third reduction: Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination, or RFE for short, is a feature reduction method that works by **recursively training** diferent sets of features and ranking them by their importance with the use of an estimator.\n",
    "\n",
    "The supervised learning estimator needs to provide information about feature importance. For the purspose of this project, we'll make use of `Logistic Regression` as the auxiliary model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "20b5KwuxgaWj"
   },
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first split the dataframe between our target variable and the variable containing our predictor features. We will choose the `RFECV` model instead of RFE because the first allows us to test cross validation. We also must to normalize our features, so we chose `RobustScaler` algorithm for this purpose. Finally, we'll use `SMOTE` technique to treat our imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gsNa7d-8n3FE"
   },
   "outputs": [],
   "source": [
    "X_3 = df_3.drop(columns = ['TARGET'])\n",
    "y_3 = df_3['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Balancing&#x27;, SMOTE(random_state=53)),\n",
       "                (&#x27;Scaler&#x27;, RobustScaler()),\n",
       "                (&#x27;Model&#x27;,\n",
       "                 RFECV(ax=&lt;AxesSubplot:&gt;, cv=3,\n",
       "                       estimator=LogisticRegression(max_iter=300,\n",
       "                                                    solver=&#x27;liblinear&#x27;),\n",
       "                       scoring=&#x27;accuracy&#x27;, step=0.1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Balancing&#x27;, SMOTE(random_state=53)),\n",
       "                (&#x27;Scaler&#x27;, RobustScaler()),\n",
       "                (&#x27;Model&#x27;,\n",
       "                 RFECV(ax=&lt;AxesSubplot:&gt;, cv=3,\n",
       "                       estimator=LogisticRegression(max_iter=300,\n",
       "                                                    solver=&#x27;liblinear&#x27;),\n",
       "                       scoring=&#x27;accuracy&#x27;, step=0.1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(random_state=53)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Model: RFECV</label><div class=\"sk-toggleable__content\"><pre>RFECV(ax=&lt;AxesSubplot:&gt;, cv=3,\n",
       "      estimator=LogisticRegression(max_iter=300, solver=&#x27;liblinear&#x27;),\n",
       "      scoring=&#x27;accuracy&#x27;, step=0.1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=300, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=300, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Balancing', SMOTE(random_state=53)),\n",
       "                ('Scaler', RobustScaler()),\n",
       "                ('Model',\n",
       "                 RFECV(ax=<AxesSubplot:>, cv=3,\n",
       "                       estimator=LogisticRegression(max_iter=300,\n",
       "                                                    solver='liblinear'),\n",
       "                       scoring='accuracy', step=0.1))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_aux = LogisticRegression(solver = 'liblinear',  max_iter = 300)\n",
    "\n",
    "rfe_model = RFECV(model_aux, scoring = 'accuracy', cv = 3, step = 0.1)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "smote_model  = SMOTE(random_state = 53, k_neighbors = 5)\n",
    "\n",
    "pipeline = Pipeline([('Balancing', smote_model), ('Scaler', scaler), ('Model', rfe_model)])\n",
    "\n",
    "pipeline.fit(X_3, y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RFECV model achieved the highest accuracy model with **11 features**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6715384351954322"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the mean of scores of the cross validation:\n",
    "\n",
    "rfe_model.cv_scores_.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the best features so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmZQuOhzrY4o",
    "outputId": "8fa7768f-90c1-452f-f1bc-1eb273de6360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features:  ['var15', 'ind_var13_largo_0', 'ind_var14_0', 'ind_var40_0', 'var36', 'ind_var43_emit_ult1', 'ind_var43_recib_ult1', 'num_meses_var5_ult3', 'num_meses_var8_ult3', 'num_meses_var12_ult3', 'num_meses_var13_corto_ult3']\n"
     ]
    }
   ],
   "source": [
    "best_features_df_3 = list(X_3.columns[rfe_model.support_])\n",
    "print('Best features: ', best_features_df_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Fourth reduction: Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble estimator **Random Forest** has the property `Feature Importance`, which returns us the features that contribute most to the reduction of the Gini impurity criterion.\n",
    "\n",
    "We'll make use again of the `Pipeline`, `RobustScaler` and  `SMOTE` methods and test the **accuracy** of the model with cross validation. Let's create a function for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_pipeline(model, X, y, scaler = RobustScaler(), sinthetic_model = SMOTE(random_state = 53, k_neighbors = 5),\n",
    "                           cv = StratifiedKFold(n_splits = 10, shuffle=True)):\n",
    "    \n",
    "    # Splitting the data with 25% test size:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 53, stratify = y)\n",
    "    \n",
    "    pipeline = Pipeline([('Balancing', sinthetic_model), ('Normalization', scaler), ('Model', model)])\n",
    "    \n",
    "    cv_result =  cross_validate(pipeline, X_train, y_train, cv = cv, return_train_score = False, scoring = 'accuracy')\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    score_pipeline = pipeline.score(X_test, y_test)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    class_rep = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return cv_result, score_pipeline, model, class_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the variables to the model with the best features from the last step:\n",
    "\n",
    "X = df_train.loc[:, best_features_df_3]\n",
    "y = df_train['TARGET']\n",
    "\n",
    "# Calling the function previously created:\n",
    "\n",
    "cv_result, score_pipeline, model, class_rep = cross_validate_pipeline(X= X, y = y, \n",
    "                                                        model = RandomForestClassifier(max_depth=6,n_jobs=-1,n_estimators=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the accuracy score of both validation set and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7802856341977209\n"
     ]
    }
   ],
   "source": [
    "print(cv_result['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7843725335438042\n"
     ]
    }
   ],
   "source": [
    "print(score_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can observe that we achieved already the minimum accuracy requested for this project.\n",
    "\n",
    "We can now plot the importance score of each feature in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_idx = model.feature_importances_.argsort()\n",
    "plt.barh(X.columns[sorted_idx], model.feature_importances_[sorted_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is interesting to note that only a few features in our dataframe are responsible for most of the power of prediction.\n",
    "\n",
    "We will set a **threshold value of 0.1** and check if we can keep reducing the dimensionality without losing accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_df_4 = list(X.columns[model.feature_importances_ > 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var15', 'var36', 'num_meses_var5_ult3']\n"
     ]
    }
   ],
   "source": [
    "print(columns_df_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing predictive models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this part of the project, we will test different algorithms using the final set of features that we found in our fourth reduction step. Our goal is to improve or at least keep our current accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the variables to the model with the best features from the fourth step:\n",
    "\n",
    "X = df_train.loc[:, columns_df_4]\n",
    "y = df_train['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establishing the chosen models to be tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic Regression': LogisticRegression(random_state = 53, max_iter = 900),\n",
    "           'KNN': KNeighborsClassifier(),\n",
    "           'Decision Tree Classifier': DecisionTreeClassifier(random_state = 53),\n",
    "           'Random Forest Classifier': RandomForestClassifier(random_state = 53,  n_estimators = 500, max_depth=6),\n",
    "           'Gradient Boosting Classifier': GradientBoostingClassifier(n_estimators = 500, random_state = 53),\n",
    "           'XGBoost Classifier': xgb.XGBClassifier(learning_rate=0.15, n_estimators=500, seed = 53)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then test our chosen models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "class_report = {}\n",
    "\n",
    "for name, method in models.items():\n",
    "    \n",
    "    cv_result, score_pipeline, model, class_rep = cross_validate_pipeline(X= X, y = y, model = method)\n",
    "    \n",
    "    results[name + '_cv_score'] = cv_result['test_score'].mean()\n",
    "    \n",
    "    results[name + '_test_score'] = score_pipeline\n",
    "    \n",
    "    class_report[name] = class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the results for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross_validation_score</th>\n",
       "      <th>Test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.650899</td>\n",
       "      <td>0.649513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.956205</td>\n",
       "      <td>0.956853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.741261</td>\n",
       "      <td>0.743699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.780620</td>\n",
       "      <td>0.790003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.762781</td>\n",
       "      <td>0.754065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>0.746067</td>\n",
       "      <td>0.739227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Cross_validation_score  Test_score\n",
       "Logistic Regression                         0.650899    0.649513\n",
       "KNN                                         0.956205    0.956853\n",
       "Decision Tree Classifier                    0.741261    0.743699\n",
       "Random Forest Classifier                    0.780620    0.790003\n",
       "Gradient Boosting Classifier                0.762781    0.754065\n",
       "XGBoost Classifier                          0.746067    0.739227"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(index = models.keys())\n",
    "\n",
    "df_results['Cross_validation_score'] = [score for name, score in results.items() if 'cv_score' in name]\n",
    "\n",
    "df_results['Test_score'] = [score for name, score in results.items() if 'cv_score' not in name]\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that the `KNN` model had the **highest scores** in both validation and testing set, followed by `Random Forest Classifier`.\n",
    "\n",
    "However, it is possible that the `KNN` is privileging the class that has more data to the detriment of balancing accuracy. Let's plot the `Classification Report` of the models to have a broader view of this situation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78     18253\n",
      "           1       0.08      0.71      0.14       752\n",
      "\n",
      "    accuracy                           0.65     19005\n",
      "   macro avg       0.53      0.68      0.46     19005\n",
      "weighted avg       0.95      0.65      0.75     19005\n",
      "\n",
      "_______________________________________________________\n",
      "\n",
      "\n",
      "KNN :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     18253\n",
      "           1       0.06      0.01      0.01       752\n",
      "\n",
      "    accuracy                           0.96     19005\n",
      "   macro avg       0.51      0.50      0.49     19005\n",
      "weighted avg       0.93      0.96      0.94     19005\n",
      "\n",
      "_______________________________________________________\n",
      "\n",
      "\n",
      "Decision Tree Classifier :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85     18253\n",
      "           1       0.10      0.65      0.17       752\n",
      "\n",
      "    accuracy                           0.74     19005\n",
      "   macro avg       0.54      0.70      0.51     19005\n",
      "weighted avg       0.95      0.74      0.82     19005\n",
      "\n",
      "_______________________________________________________\n",
      "\n",
      "\n",
      "Random Forest Classifier :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88     18253\n",
      "           1       0.11      0.64      0.19       752\n",
      "\n",
      "    accuracy                           0.79     19005\n",
      "   macro avg       0.55      0.72      0.54     19005\n",
      "weighted avg       0.95      0.79      0.85     19005\n",
      "\n",
      "_______________________________________________________\n",
      "\n",
      "\n",
      "Gradient Boosting Classifier :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86     18253\n",
      "           1       0.10      0.68      0.18       752\n",
      "\n",
      "    accuracy                           0.75     19005\n",
      "   macro avg       0.54      0.72      0.52     19005\n",
      "weighted avg       0.95      0.75      0.83     19005\n",
      "\n",
      "_______________________________________________________\n",
      "\n",
      "\n",
      "XGBoost Classifier :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.85     18253\n",
      "           1       0.10      0.66      0.17       752\n",
      "\n",
      "    accuracy                           0.74     19005\n",
      "   macro avg       0.54      0.70      0.51     19005\n",
      "weighted avg       0.95      0.74      0.82     19005\n",
      "\n",
      "_______________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, score in class_report.items():\n",
    "    \n",
    "    print(name + ' :')\n",
    "    \n",
    "    print(score)\n",
    "    \n",
    "    print('_'*55)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In fact, it is possible to observe that the `KNN` algorithm prioritized the optimization of the majority class. We could have used the `Balanced Accuracy Score` or another specific metric, however we will follow the previously established guideline.\n",
    "\n",
    "\n",
    "For this reason, and according to the results obtained previously, we chose to proceed with the model `Random Forest Classifier`. In the follow, we will try to **optimize the hyperparameters** of the chosen model with the help of the `GridSearchCV` technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;Balancing&#x27;, SMOTE(random_state=53)),\n",
       "                                       (&#x27;Scaler&#x27;, RobustScaler()),\n",
       "                                       (&#x27;Model&#x27;,\n",
       "                                        RandomForestClassifier(max_depth=6,\n",
       "                                                               n_estimators=500,\n",
       "                                                               random_state=53))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;Model__criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;Model__max_depth&#x27;: [4, 5, 6, 7, 8],\n",
       "                         &#x27;Model__min_samples_split&#x27;: [2, 3],\n",
       "                         &#x27;Model__n_estimators&#x27;: [400, 500, 600, 700]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;Balancing&#x27;, SMOTE(random_state=53)),\n",
       "                                       (&#x27;Scaler&#x27;, RobustScaler()),\n",
       "                                       (&#x27;Model&#x27;,\n",
       "                                        RandomForestClassifier(max_depth=6,\n",
       "                                                               n_estimators=500,\n",
       "                                                               random_state=53))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;Model__criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;Model__max_depth&#x27;: [4, 5, 6, 7, 8],\n",
       "                         &#x27;Model__min_samples_split&#x27;: [2, 3],\n",
       "                         &#x27;Model__n_estimators&#x27;: [400, 500, 600, 700]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Balancing&#x27;, SMOTE(random_state=53)),\n",
       "                (&#x27;Scaler&#x27;, RobustScaler()),\n",
       "                (&#x27;Model&#x27;,\n",
       "                 RandomForestClassifier(max_depth=6, n_estimators=500,\n",
       "                                        random_state=53))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(random_state=53)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=6, n_estimators=500, random_state=53)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('Balancing', SMOTE(random_state=53)),\n",
       "                                       ('Scaler', RobustScaler()),\n",
       "                                       ('Model',\n",
       "                                        RandomForestClassifier(max_depth=6,\n",
       "                                                               n_estimators=500,\n",
       "                                                               random_state=53))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'Model__criterion': ['gini', 'entropy'],\n",
       "                         'Model__max_depth': [4, 5, 6, 7, 8],\n",
       "                         'Model__min_samples_split': [2, 3],\n",
       "                         'Model__n_estimators': [400, 500, 600, 700]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_model = RandomForestClassifier(random_state = 53,  n_estimators = 500, max_depth = 6)\n",
    "\n",
    "hyperparmeters = {'Model__n_estimators': [400, 500, 600, 700],\n",
    "                 'Model__max_depth': [4, 5, 6, 7, 8],\n",
    "                 'Model__min_samples_split': [2, 3],\n",
    "                 'Model__criterion': ['gini', 'entropy']}\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "sinthetic_model  = SMOTE(random_state = 53, k_neighbors = 5)\n",
    "\n",
    "pipeline = Pipeline([('Balancing', sinthetic_model), ('Scaler', scaler), ('Model', chosen_model)])\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "otimiz = GridSearchCV(pipeline, hyperparmeters, cv = cv, n_jobs = -1, scoring = 'accuracy')\n",
    "\n",
    "otimiz.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally test our chosen model with the best hyperparmeters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_model = RandomForestClassifier(random_state = 53,  n_estimators = otimiz.best_params_['Model__n_estimators'], \n",
    "                                    max_depth = otimiz.best_params_['Model__max_depth'],\n",
    "                                    min_samples_split = otimiz.best_params_['Model__min_samples_split'],\n",
    "                                    criterion = otimiz.best_params_['Model__criterion'])\n",
    "\n",
    "cv_result, score_pipeline, model, class_rep = cross_validate_pipeline(X= X, y = y, model = opti_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8169075883786873\n"
     ]
    }
   ],
   "source": [
    "print(cv_result['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8317284925019731\n"
     ]
    }
   ],
   "source": [
    "print(score_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91     18253\n",
      "           1       0.13      0.60      0.22       752\n",
      "\n",
      "    accuracy                           0.83     19005\n",
      "   macro avg       0.56      0.72      0.56     19005\n",
      "weighted avg       0.95      0.83      0.88     19005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is essential for a financial institution that customers **dissatisfied** with its services are quickly identified and preventive measures are taken to resolve this situation.\n",
    "\n",
    "This work is essentially relevant for established banks, where the competition with new digital players requires precise initiatives in order to **retain these customers**.\n",
    "\n",
    "This project involved a typical problem within Data Science, which is the ability to **reduce the dimensionality** of the dataset, since the creation of predictive models in this situation could lead to inaccuracies in results and a decrease in decision speed.\n",
    "\n",
    "At the end of the work, we were able to train a `Random Forest` prediction model with an average **accuracy of 83%**.\n",
    "\n",
    "In order to improve the model performance, the following strategies may be further studied:\n",
    "\n",
    "* Other techniques for dimensionality reduction, like PCA, could be studied;\n",
    "* The original testing dataset could be used somehow;\n",
    "* Other oversampling and undersampling techniques could be used;\n",
    "* More models or even a blend of models could be tested."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
